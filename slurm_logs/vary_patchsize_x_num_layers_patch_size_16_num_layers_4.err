wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: sjaiswa3 (diffusion-stepbystep) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /data/user_data/mprabhud/shantanu/vlr_project_logs2/wandb/run-20250423_101056-dteh8ww3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 16x4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/diffusion-stepbystep/vlr-project
wandb: üöÄ View run at https://wandb.ai/diffusion-stepbystep/vlr-project/runs/dteh8ww3
Run id: dteh8ww3

Loaded checkpoint: /data/user_data/mprabhud/shantanu/vlr_project_logs2/vlr-project/16x4/checkpoints/last.ckpt
Ignored keys: <All keys matched successfully>

SLURM_JOB_ID: 4618853
SLURM_ARRAY_TASK_ID: N/A
/data/user_data/mprabhud/mamba/envs/vlr_project/lib/python3.13/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train.py patch_size=16 num_layers=4 exp_group=vary_p ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA L40S') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

/data/user_data/mprabhud/mamba/envs/vlr_project/lib/python3.13/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /data/user_data/mprabhud/shantanu/vlr_project_logs2/vlr-project/16x4/checkpoints exists and is not empty.
Restoring states from the checkpoint path at /data/user_data/mprabhud/shantanu/vlr_project_logs2/vlr-project/16x4/checkpoints/last.ckpt
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name            | Type             | Params | Mode 
-------------------------------------------------------------
0 | model           | ViT              | 35.4 M | train
1 | resize_image    | Compose          | 0      | train
2 | norm_image      | Compose          | 0      | train
3 | resize_and_norm | Compose          | 0      | train
4 | crit            | CrossEntropyLoss | 0      | train
-------------------------------------------------------------
35.4 M    Trainable params
0         Non-trainable params
35.4 M    Total params
141.711   Total estimated model params size (MB)
64        Modules in train mode
0         Modules in eval mode
Restored all states from the checkpoint at /data/user_data/mprabhud/shantanu/vlr_project_logs2/vlr-project/16x4/checkpoints/last.ckpt
[rank: 3] Monitored metric val/t1_acc did not improve in the last 10 records. Best score: 0.125. Signaling Trainer to stop.
[rank: 1] Monitored metric val/t1_acc did not improve in the last 10 records. Best score: 0.125. Signaling Trainer to stop.
[rank: 0] Monitored metric val/t1_acc did not improve in the last 10 records. Best score: 0.125. Signaling Trainer to stop.
[rank: 2] Monitored metric val/t1_acc did not improve in the last 10 records. Best score: 0.125. Signaling Trainer to stop.
